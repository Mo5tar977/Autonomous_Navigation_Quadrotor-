# -*- coding: utf-8 -*-
"""Avoidance_Control_PPO_Library.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TCwEA7GgpiTP4hMM80dj8f8AEKasWa5U

# Installing Packages
"""


"""**Importing libraries**


"""

import os
import tensorflow as tf
import time
from datetime import datetime
import random
import pybullet as p
import numpy as np
import matplotlib.pyplot as plt
import pybullet_envs
import gym
import torch
import torch.nn as nn
import torch.nn.functional as F
from gym import wrappers
from gym import spaces
from torch.autograd import Variable
from collections import deque
from stable_baselines3.common.env_checker import check_env
from stable_baselines3.common.cmd_util import make_vec_env # Module cmd_util will be renamed to env_util https://github.com/DLR-RM/stable-baselines3/pull/197
from stable_baselines3.common.vec_env import SubprocVecEnv, VecTransposeImage
from stable_baselines3.common.utils import set_random_seed
from stable_baselines3.common.noise import NormalActionNoise
from stable_baselines3 import A2C
from stable_baselines3 import PPO
from stable_baselines3 import SAC
from stable_baselines3 import TD3
from stable_baselines3 import DDPG
from stable_baselines3.common.policies import ActorCriticPolicy as a2cppoMlpPolicy
from stable_baselines3.common.policies import ActorCriticCnnPolicy as a2cppoCnnPolicy
from stable_baselines3.sac.policies import SACPolicy as sacMlpPolicy
from stable_baselines3.sac import CnnPolicy as sacCnnPolicy
from stable_baselines3.td3 import MlpPolicy as td3ddpgMlpPolicy
from stable_baselines3.td3 import CnnPolicy as td3ddpgCnnPolicy
from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback, EvalCallback, StopTrainingOnRewardThreshold, CallbackList



from gym_pybullet_drones.envs.single_agent_rl.TakeoffAviary import TakeoffAviary
from gym_pybullet_drones.envs.single_agent_rl.HoverAviary import HoverAviary
from gym_pybullet_drones.envs.BaseAviary import DroneModel, Physics, BaseAviary



"""**Creating the Environment**"""

class DroneAviary(BaseAviary):
    """Multi-drone environment class for control applications."""

    ################################################################################

    def __init__(self,
                 drone_model: DroneModel=DroneModel.CF2X,
                 num_drones: int=1,
                 neighbourhood_radius: float=np.inf,
                 initial_xyzs=None,
                 initial_rpys=None,
                 physics: Physics=Physics.PYB,
                 freq: int=250,
                 aggregate_phy_steps: int=1,
                 gui=False,
                 record=False,
                 obstacles=False,
                 user_debug_gui=True,
                 randomize_init=False,
                 position_agent=None
                 ):
        """Initialization of an aviary environment for control applications.

        Parameters
        ----------
        drone_model : DroneModel, optional
            The desired drone type (detailed in an .urdf file in folder `assets`).
        num_drones : int, optional
            The desired number of drones in the aviary.
        neighbourhood_radius : float, optional
            Radius used to compute the drones' adjacency matrix, in meters.
        initial_xyzs: ndarray | None, optional
            (NUM_DRONES, 3)-shaped array containing the initial XYZ position of the drones.
        initial_rpys: ndarray | None, optional
            (NUM_DRONES, 3)-shaped array containing the initial orientations of the drones (in radians).
        physics : Physics, optional
            The desired implementation of PyBullet physics/custom dynamics.
        freq : int, optional
            The frequency (Hz) at which the physics engine steps.
        aggregate_phy_steps : int, optional
            The number of physics steps within one call to `BaseAviary.step()`.
        gui : bool, optional
            Whether to use PyBullet's GUI.
        record : bool, optional
            Whether to save a video of the simulation in folder `files/videos/`.
        obstacles : bool, optional
            Whether to add obstacles to the simulation.
        user_debug_gui : bool, optional
            Whether to draw the drones' axes and the GUI RPMs sliders.

        """
        super().__init__(drone_model=drone_model,
                         num_drones=num_drones,
                         neighbourhood_radius=neighbourhood_radius,
                         initial_xyzs=initial_xyzs,
                         initial_rpys=initial_rpys,
                         physics=physics,
                         freq=freq,
                         aggregate_phy_steps=aggregate_phy_steps,
                         gui=gui,
                         record=record,
                         obstacles=obstacles,
                         user_debug_gui=user_debug_gui
                         )
        self.EPISODE_LEN_SEC = 12
        self.desPos = np.array([0.,0.,0.])
        self.P1 = np.array([0,0,0])     #Penalty parameters multiplied by position error
        self.P2 = np.array([0,0,0])     #Penalty parameters multiplied by angular error
        self.P3 = 0
        self.P4 = 0                     #Penalty parameters multiplied by velocity error
        self.P5 = np.array([0,0,0])     #Penalty parameters multiplied by obstacle error
        self.maxX = 3.
        self.minX = -3.
        self.maxY = 3.
        self.minY = -3.
        self.maxZ = 4.
        self.minZ = 0.3
        self.lastActionNorm = np.array([0.,0.,0.,0.])
        self.currentActionNorm = np.array([0.,0.,0.,0.])
        self.obsInfo = np.array([0., 0., 2., 0.5]) # information of the sphere surounding the obstacle [x y z Redius]
        self.randomize_init = randomize_init 
        self.position_agent = position_agent
        self.trajectory = np.array([])
        self.counterTraj = 0
        self.deflection = np.array([0.])


    #################################################################################
    def _actionSpace(self):
        """Returns the action space of the environment.

        Returns
        -------
        dict[str, ndarray]
            A Dict of Box(4,) with NUM_DRONES entries,
            indexed by drone Id in string format.

        """
        #### Action vector ######## P0            P1            P2            P3
        #act_lower_bound = np.array([-1.,           -1.,           -1.,           -1.])
        #act_upper_bound = np.array([ 1.,            1.,            1.,            1.])
        act_lower_bound = np.array([-1.])
        act_upper_bound = np.array([ 1.])
        total_actions = spaces.Dict({str(i): spaces.Box(low=act_lower_bound,
                                               high=act_upper_bound,
                                               dtype=np.float32
                                               ) for i in range(self.NUM_DRONES)})
        return total_actions["0"]
    
    ################################################################################
    ################################################################################

    def _addObstacles(self):
        """Add obstacles to the environment.

        Only if the observation is of type RGB, 4 landmarks are added.
        Overrides BaseAviary's method.

        """
        x_obstacle = self.obsInfo[0]
        y_obstacle = self.obsInfo[1]
        z_obstacle = self.obsInfo[2]
        r_obstacle = self.obsInfo[3]
        
        if r_obstacle <= 0.1:
            p.loadURDF("custom_sphere_0.1.urdf",
                           [x_obstacle, y_obstacle, z_obstacle],
                           p.getQuaternionFromEuler([0, 0, 0]),
                           physicsClientId=self.CLIENT
                           )
        elif r_obstacle <= 0.3:
            p.loadURDF("custom_sphere_0.3.urdf",
                           [x_obstacle, y_obstacle, z_obstacle],
                           p.getQuaternionFromEuler([0, 0, 0]),
                           physicsClientId=self.CLIENT
                           )
        elif r_obstacle <= 0.5:
            p.loadURDF("custom_sphere_0.5.urdf",
                           [x_obstacle, y_obstacle, z_obstacle],
                           p.getQuaternionFromEuler([0, 0, 0]),
                           physicsClientId=self.CLIENT
                           )
        else:
            p.loadURDF("custom_sphere_0.75.urdf",
                           [x_obstacle, y_obstacle, z_obstacle],
                           p.getQuaternionFromEuler([0, 0, 0]),
                           physicsClientId=self.CLIENT
                           )



    ################################################################################
    ################################################################################

    def reset(self):
        """Resets the environment.

        Returns
        -------
        ndarray | dict[..]
            The initial observation, check the specific implementation of `_computeObs()`
            in each subclass for its format.

        """
        p.resetSimulation(physicsClientId=self.CLIENT)
        #### Housekeeping ##########################################
        self._housekeeping()
        #### Update and store the drones kinematic information #####
        self._updateAndStoreKinematicInformation()
        #### Start video recording #################################
        self._startVideoRecording()
        #### Return the initial observation ########################
        self.reset_param()
        return self._computeObs()
    
    ################################################################################
    ################################################################################

    def updateTraj(self,traj):
        """Update the Trajectory.

        Returns
        -------
        Nothing

        """

        self.trajectory = traj
    
    ################################################################################
    ################################################################################

    def updateBound(self,bound):
        """Update the Bounderies of the learning Zone.

        Returns
        -------
        Nothing

        """
        #bound =[max x   min x   max y   min y   max z   min z]

        self.maxX, self.minX, self.maxY, self.minY, self.maxZ, self.minZ = bound[0:6]
    
    ################################################################################
    ################################################################################

    def updatePar(self, P1, P2, P3, P4, P5):
        """Update the Desired Position.

        Returns
        -------
        Nothing

        """
        self.P1[0:3] = P1[0:3]
        self.P2[0:3] = P2[0:3]
        self.P3 = P3
        self.P4 = P4
        self.P5[0:3] = P5[0:3]
    
    ################################################################################
    ################################################################################

    def randObs(self):
        """Update the Obstacle Position.

        Returns
        -------
        Nothing

        """
        #radius = random.random() * 0.5 + 0.001    #Range from 0.001 to 0.251
        #self.obsInfo[3] = radius
        #y_obstacle = random.randint(1,5)
        #self.obsInfo[1] = y_obstacle * 0.35 - 1.05  # Range from -0.7 to 0.7
        
        y_obstacle_array = np.array([-1, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,
                                      1,  0.9,  0.8,  0.7,  0.6,  0.5,  0.4,  0.3,  0.2,  0.1])
        y_obstacle_index = random.randint(1,20) - 1
        #y_obstacle = random.random() * 2 - 1
        
        r_obstacle_array = np.array([0.3, 0.5, 0.5, 0.75])
        r_obstacle_index = random.randint(1,4) - 1
        
        self.obsInfo[1] = y_obstacle_array[y_obstacle_index]
        self.obsInfo[3] = r_obstacle_array[r_obstacle_index]
        

        #return radius 
    
    ################################################################################

    ################################################################################

    def randInit(self):
        """Update the Desired Position.

        Returns
        -------
        Nothing

        """
        #quad = random.randint(1,2)
        quad = 2
        radius = self.obsInfo[3] + 1.

        meanXpos = (self.maxX + radius) / 2 
        stdXpos = (self.maxX - radius) * 0.2
        meanYpos = (self.maxY + radius) / 2 
        stdYpos = (self.maxY - radius) * 0.2
        meanZpos = (self.maxZ + (self.obsInfo[2] + radius)) / 2 
        stdZpos = (self.maxZ - (self.obsInfo[2] + radius)) * 0.2

        meanXneg = (-1 * radius + self.minX) / 2 
        stdXneg = (-1 * radius - self.minX) * 0.2
        meanYneg = (-1 * radius + self.minY) / 2 
        stdYneg = (-1 * radius - self.minY) * 0.2
        meanZneg = ((self.obsInfo[2] - radius) + self.minZ) / 2 
        stdZneg = ((self.obsInfo[2] - radius) - self.minZ) * 0.2

        meanX = (self.maxX + self.minX) / 2 
        stdX = (self.maxX - self.minX) * 0.2
        meanY = (self.maxY + self.minY) / 2 
        stdY = (self.maxY - self.minY) * 0.2
        meanZ = (self.maxZ + self.minZ) / 2 
        stdZ = (self.maxZ - self.minZ) * 0.2


        if quad == 1:
          self.INIT_XYZS[0][0] = 2.5
          self.INIT_XYZS[0][1] = 0.
          self.INIT_XYZS[0][2] = 2.
          #self.INIT_XYZS[0][0] = np.random.normal(meanXpos,stdXpos,1).clip(radius,self.maxX)
          #self.INIT_XYZS[0][1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          #self.INIT_XYZS[0][2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 2:
          self.INIT_XYZS[0][0] = -2.5
          self.INIT_XYZS[0][1] = 0.
          self.INIT_XYZS[0][2] = 2.
          #self.INIT_XYZS[0][0] = np.random.normal(meanXneg,stdXneg,1).clip(self.minX,(-1 * radius))
          #self.INIT_XYZS[0][1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          #self.INIT_XYZS[0][2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 3:
          self.INIT_XYZS[0][0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          self.INIT_XYZS[0][1] = np.random.normal(meanYpos,stdYpos,1).clip(radius,self.maxY)
          self.INIT_XYZS[0][2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 4:
          self.INIT_XYZS[0][0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          self.INIT_XYZS[0][1] = np.random.normal(meanYneg,stdYneg,1).clip(self.minY,(-1 * radius))
          self.INIT_XYZS[0][2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 5:
          self.INIT_XYZS[0][0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          self.INIT_XYZS[0][1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          self.INIT_XYZS[0][2] = np.random.normal(meanZpos,stdZpos,1).clip((self.obsInfo[2] + radius),self.maxZ)

        else:
          self.INIT_XYZS[0][0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          self.INIT_XYZS[0][1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          self.INIT_XYZS[0][2] = np.random.normal(meanZneg,stdZneg,1).clip(self.minZ,(self.obsInfo[2] - radius))
          

        self.INIT_RPYS[0] = np.random.normal(0,4 * (np.pi/180),3).clip(-8 * (np.pi/180),8 * (np.pi/180))

        return self.INIT_XYZS[0], self.INIT_RPYS[0]
    
    ################################################################################    
    ################################################################################

    def randDes(self):
        """Update the Desired Position.

        Returns
        -------
        Nothing

        """
        #quad = random.randint(1,2)
        quad = 1
        radius = self.obsInfo[3] + 1.

        meanXpos = (self.maxX + radius) / 2 
        stdXpos = (self.maxX - radius) * 0.2
        meanYpos = (self.maxY + radius) / 2 
        stdYpos = (self.maxY - radius) * 0.2
        meanZpos = (self.maxZ + (self.obsInfo[2] + radius)) / 2 
        stdZpos = (self.maxZ - (self.obsInfo[2] + radius)) * 0.2

        meanXneg = (-1 * radius + self.minX) / 2 
        stdXneg = (-1 * radius - self.minX) * 0.2
        meanYneg = (-1 * radius + self.minY) / 2 
        stdYneg = (-1 * radius - self.minY) * 0.2
        meanZneg = ((self.obsInfo[2] - radius) + self.minZ) / 2 
        stdZneg = ((self.obsInfo[2] - radius) - self.minZ) * 0.2

        meanX = (self.maxX + self.minX) / 2 
        stdX = (self.maxX - self.minX) * 0.2
        meanY = (self.maxY + self.minY) / 2 
        stdY = (self.maxY - self.minY) * 0.2
        meanZ = (self.maxZ + self.minZ) / 2 
        stdZ = (self.maxZ - self.minZ) * 0.2


        if quad == 1:
          desPos = np.array([0.,0.,0.])
          desPos[0] = 2.4
          desPos[1] = 0.
          desPos[2] = 2.
          #desPos[0] = np.random.normal(meanXpos,stdXpos,1).clip(radius,self.maxX)
          #desPos[1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          #desPos[2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 2:
          desPos = np.array([0.,0.,0.])
          desPos[0] = -2.4
          desPos[1] = 0.
          desPos[2] = 2.
          #desPos[0] = np.random.normal(meanXneg,stdXneg,1).clip(self.minX,(-1 * radius))
          #desPos[1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          #desPos[2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 3:
          desPos = np.array([0.,0.,0.])
          desPos[0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          desPos[1] = np.random.normal(meanYpos,stdYpos,1).clip(radius,self.maxY)
          desPos[2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 4:
          desPos = np.array([0.,0.,0.])
          desPos[0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          desPos[1] = np.random.normal(meanYneg,stdYneg,1).clip(self.minY,(-1 * radius))
          desPos[2] = np.random.normal(meanZ,stdZ,1).clip(self.minZ,self.maxZ)

        elif quad == 5:
          desPos = np.array([0.,0.,0.])
          desPos[0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          desPos[1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          desPos[2] = np.random.normal(meanZpos,stdZpos,1).clip((self.obsInfo[2] + radius),self.maxZ)

        else:
          desPos = np.array([0.,0.,0.])
          desPos[0] = np.random.normal(meanX,stdX,1).clip(self.minX,self.maxX)
          desPos[1] = np.random.normal(meanY,stdY,1).clip(self.minY,self.maxY)
          desPos[2] = np.random.normal(meanZneg,stdZneg,1).clip(self.minZ,(self.obsInfo[2] - radius))
          

        self.updateDes(desPos)

        return desPos
    
    ################################################################################
    ################################################################################

    def updateDes(self, desPos):
        """Update the Desired Position.

        Returns
        -------
        Nothing

        """
        self.desPos[0:3] = desPos[0:3]
    
    ################################################################################
    ################################################################################

    def updateInit(self, initPos, initAng):
        """Update the Initial Position.

        Returns
        -------
        Nothing

        """
        self.INIT_XYZS[0][0:3] = initPos[0:3]
        self.INIT_RPYS[0][0:3] = initAng[0:3]

    
    ################################################################################
    ################################################################################

    def updateObs(self, radius):
        """Update the Radius.

        Returns
        -------
        Nothing

        """
        self.obsInfo[3] = radius

    
    ################################################################################

    def _observationSpace(self):
        """Returns the observation space of the environment.

        Returns
        -------
        dict[str, dict[str, ndarray]]
            A Dict with NUM_DRONES entries indexed by Id in string format,
            each a Dict in the form {Box(20,), MultiBinary(NUM_DRONES)}.

        """
        """
        #### Observation vector ### X        Y        Z       Q1   Q2   Q3   Q4   R       P       Y       VX       VY       VZ       WX       WY       WZ       P0            P1            P2            P3
        obs_lower_bound = np.array([-np.inf, -np.inf, 0.,     -1., -1., -1., -1., -np.pi, -np.pi, -np.pi, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, 0.,           0.,           0.,           0.])
        obs_upper_bound = np.array([np.inf,  np.inf,  np.inf, 1.,  1.,  1.,  1.,  np.pi,  np.pi,  np.pi,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  self.MAX_RPM, self.MAX_RPM, self.MAX_RPM, self.MAX_RPM])
        total_states = spaces.Dict({str(i): spaces.Dict({"state": spaces.Box(low=obs_lower_bound,
                                                                     high=obs_upper_bound,
                                                                     dtype=np.float32
                                                                     ),
                                                 "neighbors": spaces.MultiBinary(self.NUM_DRONES)
                                                 }) for i in range(self.NUM_DRONES)})
        """
        """
        #### Observation vector ### X        Y        Z         R       P       Y       VX       VY       VZ       WX       WY       WZ        DX         DY        DZ
        obs_lower_bound = np.array([-np.inf, -np.inf, 0.,     -np.pi, -np.pi, -np.pi, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf,  -np.inf,  -np.inf])
        obs_upper_bound = np.array([ np.inf,  np.inf,  np.inf, np.pi,  np.pi,  np.pi,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,   np.inf,   np.inf])
        total_states = spaces.Dict({str(i): spaces.Dict({"state": spaces.Box(low=obs_lower_bound,
                                                                     high=obs_upper_bound,
                                                                     dtype=np.float32
                                                                     ),
                                                 "neighbors": spaces.MultiBinary(self.NUM_DRONES)
                                                 }) for i in range(self.NUM_DRONES)})
        return total_states["0"]["state"]
        """
        """
        #### Observation vector ###   R       P       Y       VX       VY       VZ       WX       WY       WZ        DX         DY        DZ    DXobs     DYobs     DZobs     radius
        obs_lower_bound = np.array([-np.pi, -np.pi, -np.pi, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf,  -np.inf,  -np.inf, -np.inf,  -np.inf,  -np.inf,  -np.inf])
        obs_upper_bound = np.array([ np.pi,  np.pi,  np.pi,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,   np.inf,   np.inf,  np.inf,   np.inf,   np.inf,   np.inf])
        total_states = spaces.Dict({str(i): spaces.Dict({"state": spaces.Box(low=obs_lower_bound,
                                                                     high=obs_upper_bound,
                                                                     dtype=np.float32
                                                                     ),
                                                 "neighbors": spaces.MultiBinary(self.NUM_DRONES)
                                                 }) for i in range(self.NUM_DRONES)})
        return total_states["0"]["state"]
        """
        #### Observation vector ###  offsetY  Radius   DXobs    DYobs    DZobs     VX       VY       VZ        DX         DY        DZ
        obs_lower_bound = np.array([-np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf,  -np.inf,  -np.inf, -np.inf])
        obs_upper_bound = np.array([ np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,  np.inf,   np.inf,   np.inf,  np.inf])
        total_states = spaces.Dict({str(i): spaces.Dict({"state": spaces.Box(low=obs_lower_bound,
                                                                     high=obs_upper_bound,
                                                                     dtype=np.float32
                                                                     ),
                                                 "neighbors": spaces.MultiBinary(self.NUM_DRONES)
                                                 }) for i in range(self.NUM_DRONES)})
        return total_states["0"]["state"]

    ################################################################################

    def _computeObs(self):

        """Returns the current observation of the environment.

        For the value of key "state", see the implementation of `_getDroneStateVector()`,
        the value of key "neighbors" is the drone's own row of the adjacency matrix.

        Returns
        -------
        dict[str, dict[str, ndarray]]
            A Dict with NUM_DRONES entries indexed by Id in string format,
            each a Dict in the form {Box(20,), MultiBinary(NUM_DRONES)}.

        """
        if self.counterTraj < np.shape(self.trajectory)[0]:
            self.updateDes(self.trajectory[self.counterTraj])
            self.counterTraj += 1
            
        adjacency_mat = self._getAdjacencyMatrix()
        total_obs = {str(i): {"state": self._getDroneStateVector(i), "neighbors": adjacency_mat[i, :]} for i in range(self.NUM_DRONES)}
        env_obs = total_obs["0"]["state"]
        errPos = env_obs[0:3] - self.desPos[0:3]
        errObs = env_obs[0:3] - self.obsInfo[0:3]
        


        #return np.hstack([obs[7:10], obs[10:13], obs[13:16],  errPos[0:3], errObs[0:3], self.obsInfo[3]]).reshape(16,)
        return np.hstack([self.deflection[0], self.obsInfo[3], errObs[0:3], env_obs[10:13], errPos[0:3]]).reshape(11,)

    ################################################################################
    def computeZw(self, current):

        start = self.INIT_XYZS[0]
        end = self.desPos
        obstacle = self.obsInfo[0:3]

    
        num = np.dot((current - start),(obstacle - start))
        den = np.sqrt( np.sum( (current-start)**2 ) )

        if den != 0:
          s = num / (den**2)
        else:
          s = 0
        
        if s <= 0:
          x = start
        elif s >= 1:
          x = current
        else:
          x = start + s * (current-start)

        zw1 = np.sqrt( np.sum( (x-obstacle)**2 ) )

        num = np.dot((end - current),(obstacle - current))
        den = np.sqrt( np.sum( (end-current)**2 ) )

        if den != 0:
          s = num / (den**2)
        else:
          s = 0
    
        if s <= 0:
          x = current + s * (end-current)
        elif s >= 1:
          x = current + s * (end-current)
        else:
          x = current + s * (end-current)

        zw2 = np.sqrt( np.sum( (x-obstacle)**2 ) )

        #return np.min([zw1,zw2])
        return zw2

    ################################################################################
    
    def computePw(self, current):

        start = self.INIT_XYZS[0]
        end = self.desPos

        pw = np.sqrt(np.sum((start-current)**2)) + np.sqrt(np.sum((end-current)**2))

        return pw

    ################################################################################

    def _preprocessAction(self,
                          action
                          ):
      
        """Pre-processes the action passed to `.step()` into motors' RPMs.

        Clips and converts a dictionary into a 2D array.

        Parameters
        ----------
        action : dict[str, ndarray]
            The (unbounded) input action for each drone, to be translated into feasible RPMs.

        Returns
        -------
        ndarray
            (NUM_DRONES, 4)-shaped array of ints containing to clipped RPMs
            commanded to the 4 motors of each drone.

        """
        #clipped_action = np.zeros((self.NUM_DRONES, 4))
        #for k, v in action.items():
        #    clipped_action[int(k), :] = np.clip(np.array(v), 0, self.MAX_RPM)
        #return clipped_action
        """
        Should modify the self.desPos
        self.desPos = 
        """
        #return np.array((self.MAX_RPM / 2) * (1 + action))
        self.deflection[0] = self.deflection[0] + action * (1 / self.SIM_FREQ)
        state = self._getDroneStateVector(0)
        modified_desired = np.array([self.desPos[0], self.desPos[1] + self.deflection[0], self.desPos[2]])
        errPos_position_agent = state[0:3] - modified_desired[0:3]
        obs_position_agent = np.hstack([state[7:10], state[10:13], state[13:16], errPos_position_agent[0:3]]).reshape(12,)
        
        action_position_agent, _states = self.position_agent.predict(obs_position_agent[0:12],
                                        deterministic=True # OPTIONAL 'deterministic=False'
                                        )
        return np.array(self.HOVER_RPM * (1 + 0.15 * action_position_agent))

    ################################################################################

    def _computeReward(self):
        """Computes the current reward value(s).

        Unused as this subclass is not meant for reinforcement learning.

        Returns
        -------
        int
            Dummy value.

        """
        state = self._getDroneStateVector(0)

        x,y,z = state[0:3]
        r = self.obsInfo[3]
        rBanned = r + 0.25
        rSafe = r + 0.5

        obsErr = np.sqrt(np.sum(np.square(self.obsInfo[0:3]-state[0:3])))
        #desiredErr = np.sqrt(np.sum(np.square(self.desPos[0:3]-state[0:3])))
        deflectionErr = np.abs(self.deflection[0])
        terminalReward = 0
        
        # if deflectionErr <= 0.1:
        #     terminalReward = 4
    
        
        if obsErr <= rBanned:
            reward = -2000
            
        elif obsErr <= rSafe:
            reward = -50
            
        else:
            reward = -10 * deflectionErr + 10 
            
        return reward

    ################################################################################
    
    def _computeDone(self):
        """Computes the current done value(s).

        Unused as this subclass is not meant for reinforcement learning.

        Returns
        -------
        bool
            Dummy value.

        """
        state = self._getDroneStateVector(0)

        x,y,z = state[0:3]
        roll,pitch,yaw = state[7:10]
        rObs = self.obsInfo[3]
        obsErr = np.sqrt(np.sum(np.square(self.obsInfo[0:3]-state[0:3])))
        
        #or (np.array_equiv(state[0:3],self.obsInfo[0:3]))
        if (x > self.maxX or x < self.minX) or (y > self.maxY or y < self.minY) or (z > self.maxZ or z < self.minZ):
          if self.randomize_init:
            updateAll(self)
          
          return True
      
        elif (roll > np.pi/2 or roll < -np.pi/2) or (pitch > np.pi/2 or pitch < -np.pi/2) or (yaw > np.pi/2 or yaw < -np.pi/2):
          if self.randomize_init:
            updateAll(self)
          
          return True
      
        elif obsErr <= rObs + 0.25:
          if self.randomize_init:
            updateAll(self)
          
          return True
      
        elif self.step_counter/self.SIM_FREQ > self.EPISODE_LEN_SEC:
          if self.randomize_init:
            updateAll(self)
          
          return True
      
        else:
          return False

    ################################################################################
    
    def _computeInfo(self):
        """Computes the current info dict(s).

        Unused as this subclass is not meant for reinforcement learning.

        Returns
        -------
        dict[str, int]
            Dummy value.

        """
        return {"answer": 42} #### Calculated by the Deep Thought supercomputer in 7.5M years
    ################################################################################
    
    def update_env(self):
        """ Called at the end of an episode """
        updateAll(self)
    ################################################################################
    
    def reset_param(self):
        """ Called at the end of an episode """
        self.counterTraj = 0
        self.deflection = np.array([0.])
        
################################################################################
def obstacleExist(point1, point2, radius):
    obstacle = np.array([0., 0., 2.])
    num = np.dot((point2 - point1),(obstacle - point1))
    den = np.sqrt( np.sum( (point2-point1)**2 ) )

    if den != 0:
      s = num / (den**2)
    else:
      s = 0
        
    if s <= 0:
      x = point1
    elif s >= 1:
      x = point2
    else:
      x = point1 + s * (point2-point1)

    distance = np.sqrt( np.sum( (x-obstacle)**2 ) )
    
    if distance <= radius + 0.25 :   
      return True

    else:
      return False
################################################################################
################################################################################
def updateAll(env):

    updateFlag = False
  
    while not updateFlag:
        rr  = env.obsInfo[3]
        dd = env.randDes()
        ii, _ = env.randInit()
        updateFlag = obstacleExist(ii, dd, rr)
    
    new_trajectory = createTrajectory(np.array([ii]), dd, 0.002)
    env.updateTraj(new_trajectory)
    env.randObs()
################################################################################
################################################################################
def createTrajectory(initial, target, inc):
    
    step = np.abs((target - initial)) / inc
    step = np.max(step)
    inc = (target - initial) / step
    traj = initial
    
    for i in range(int(step)):
        initial[0] = initial[0] + inc
        traj = np.append(traj, initial, axis=0)
        
    return traj[1:]
################################################################################
